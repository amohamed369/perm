---
phase: 09-feature-completion
plan: 01
type: execute
---

<objective>
Set up database schema and webhook endpoint for Google Calendar two-way sync.

Purpose: Create the foundational infrastructure needed for receiving calendar push notifications.
Output: Migration for sync channels table, webhook endpoint, and channel CRUD operations.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

**Prior decisions affecting this phase:**
- Phase 6.1: Config loading uses settings.* not os.getenv()
- Phase 7: Sanitization patterns established for frontend

**Codebase context:**
@backend/app/services/calendar_service.py
@backend/app/services/calendar_integration.py
@backend/app/api/google_services.py

**Research findings (Google Calendar Push Notifications):**
- Webhooks require HTTPS endpoint with valid SSL
- Channels expire in ~7 days, require manual renewal
- Notifications contain headers only - must use sync tokens to fetch changes
- Must store: channel_id, resource_id, sync_token, expiration_timestamp
- 410 GONE error means sync token expired - requires full resync
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create calendar_sync_channels migration</name>
  <files>backend/migrations/025_calendar_sync_channels.sql</files>
  <action>
Create SQL migration for calendar sync channels table:

```sql
-- Table to track Google Calendar push notification channels
CREATE TABLE IF NOT EXISTS calendar_sync_channels (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES perm_users(id) ON DELETE CASCADE,
    calendar_id VARCHAR(255) NOT NULL DEFAULT 'primary',
    channel_id VARCHAR(64) UNIQUE NOT NULL,
    resource_id VARCHAR(255) NOT NULL,
    sync_token TEXT,
    expiration_timestamp BIGINT NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    last_notification_at TIMESTAMP WITH TIME ZONE,
    UNIQUE(user_id, calendar_id)
);

-- Index for finding expiring channels
CREATE INDEX idx_channels_expiration ON calendar_sync_channels(expiration_timestamp);

-- Index for webhook lookups
CREATE INDEX idx_channels_channel_id ON calendar_sync_channels(channel_id);

-- RLS policies
ALTER TABLE calendar_sync_channels ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can view own channels"
    ON calendar_sync_channels FOR SELECT
    USING (auth.uid() = user_id);

CREATE POLICY "Users can insert own channels"
    ON calendar_sync_channels FOR INSERT
    WITH CHECK (auth.uid() = user_id);

CREATE POLICY "Users can update own channels"
    ON calendar_sync_channels FOR UPDATE
    USING (auth.uid() = user_id);

CREATE POLICY "Users can delete own channels"
    ON calendar_sync_channels FOR DELETE
    USING (auth.uid() = user_id);
```

Also add sync_token column to cases table for per-case event tracking:
```sql
-- Track last sync for each case's calendar events
ALTER TABLE cases ADD COLUMN IF NOT EXISTS calendar_last_synced_at TIMESTAMP WITH TIME ZONE;
```
  </action>
  <verify>SQL syntax validation - can be tested when applied to test Supabase</verify>
  <done>Migration file created with proper RLS policies</done>
</task>

<task type="auto">
  <name>Task 2: Create webhook endpoint</name>
  <files>backend/app/api/webhooks.py</files>
  <action>
Create new API router for webhooks:

```python
"""
Webhook handlers for external service notifications
"""
import logging
from fastapi import APIRouter, Request, HTTPException, BackgroundTasks
from app.db.supabase import get_supabase_client

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/webhooks", tags=["webhooks"])


@router.post("/google-calendar")
async def google_calendar_webhook(
    request: Request,
    background_tasks: BackgroundTasks
):
    """
    Handle Google Calendar push notifications.

    Google sends POST with headers only (no body):
    - X-Goog-Resource-State: sync | exists | not_exists
    - X-Goog-Channel-ID: our channel UUID
    - X-Goog-Resource-ID: Google's resource identifier
    - X-Goog-Channel-Token: optional verification token
    - X-Goog-Message-Number: notification sequence (non-sequential)
    """
    # Extract headers
    resource_state = request.headers.get("X-Goog-Resource-State")
    channel_id = request.headers.get("X-Goog-Channel-ID")
    resource_id = request.headers.get("X-Goog-Resource-ID")
    token = request.headers.get("X-Goog-Channel-Token")

    logger.info(
        f"Calendar webhook: state={resource_state}, "
        f"channel={channel_id}, resource={resource_id}"
    )

    if not channel_id:
        raise HTTPException(status_code=400, detail="Missing channel ID")

    # Verify token matches expected format
    expected_token = f"perm-tracker-{channel_id}"
    if token and token != expected_token:
        logger.warning(f"Invalid webhook token for channel {channel_id}")
        raise HTTPException(status_code=401, detail="Invalid token")

    # Acknowledge sync (channel creation confirmation)
    if resource_state == "sync":
        logger.info(f"Channel {channel_id} sync acknowledged")
        return {"status": "sync_acknowledged"}

    # Handle calendar changes
    if resource_state == "exists":
        # Process changes asynchronously to return 200 quickly
        background_tasks.add_task(
            process_calendar_changes,
            channel_id,
            resource_id
        )
    elif resource_state == "not_exists":
        # Resource was deleted - handle if needed
        logger.info(f"Resource deleted for channel {channel_id}")

    return {"status": "ok"}


async def process_calendar_changes(channel_id: str, resource_id: str):
    """
    Fetch and process calendar changes using sync token.
    Called as background task after webhook received.
    """
    from app.services.calendar_sync_service import CalendarSyncService

    try:
        await CalendarSyncService.process_webhook_notification(
            channel_id=channel_id,
            resource_id=resource_id
        )
    except Exception as e:
        logger.error(f"Error processing calendar changes for {channel_id}: {e}")
```

Register router in main.py by adding:
```python
from app.api.webhooks import router as webhooks_router
app.include_router(webhooks_router, prefix="/api")
```
  </action>
  <verify>Backend starts without import errors: `cd backend && python -c "from app.api.webhooks import router"`</verify>
  <done>Webhook endpoint created and registered in main.py</done>
</task>

<task type="auto">
  <name>Task 3: Add channel CRUD operations</name>
  <files>backend/app/services/calendar_sync_service.py</files>
  <action>
Create new service for calendar sync channel management:

```python
"""
Calendar Sync Service
Handles Google Calendar push notification channels and two-way sync
"""
import logging
import uuid
from datetime import datetime, timedelta
from typing import Optional, Dict, List
from app.db.supabase import get_supabase_client
from app.config import settings

logger = logging.getLogger(__name__)


class CalendarSyncService:
    """Service for managing calendar sync channels and processing notifications"""

    @staticmethod
    def get_channel(channel_id: str) -> Optional[Dict]:
        """Get channel by channel_id"""
        supabase = get_supabase_client()
        response = (
            supabase.table("calendar_sync_channels")
            .select("*")
            .eq("channel_id", channel_id)
            .single()
            .execute()
        )
        return response.data if response.data else None

    @staticmethod
    def get_user_channel(user_id: str, calendar_id: str = "primary") -> Optional[Dict]:
        """Get channel for a specific user and calendar"""
        supabase = get_supabase_client()
        response = (
            supabase.table("calendar_sync_channels")
            .select("*")
            .eq("user_id", user_id)
            .eq("calendar_id", calendar_id)
            .single()
            .execute()
        )
        return response.data if response.data else None

    @staticmethod
    def create_channel(
        user_id: str,
        calendar_id: str,
        channel_id: str,
        resource_id: str,
        expiration_timestamp: int,
        sync_token: Optional[str] = None
    ) -> Dict:
        """Create a new sync channel record"""
        supabase = get_supabase_client()

        data = {
            "user_id": user_id,
            "calendar_id": calendar_id,
            "channel_id": channel_id,
            "resource_id": resource_id,
            "expiration_timestamp": expiration_timestamp,
            "sync_token": sync_token,
        }

        response = (
            supabase.table("calendar_sync_channels")
            .upsert(data, on_conflict="user_id,calendar_id")
            .execute()
        )

        logger.info(f"Created/updated channel {channel_id} for user {user_id}")
        return response.data[0] if response.data else data

    @staticmethod
    def update_sync_token(channel_id: str, sync_token: str):
        """Update sync token after processing changes"""
        supabase = get_supabase_client()

        supabase.table("calendar_sync_channels").update({
            "sync_token": sync_token,
            "last_notification_at": datetime.utcnow().isoformat()
        }).eq("channel_id", channel_id).execute()

        logger.debug(f"Updated sync token for channel {channel_id}")

    @staticmethod
    def delete_channel(channel_id: str):
        """Delete a sync channel"""
        supabase = get_supabase_client()

        supabase.table("calendar_sync_channels").delete().eq(
            "channel_id", channel_id
        ).execute()

        logger.info(f"Deleted channel {channel_id}")

    @staticmethod
    def get_expiring_channels(within_days: int = 2) -> List[Dict]:
        """Get channels expiring within specified days"""
        supabase = get_supabase_client()

        cutoff = int((datetime.utcnow() + timedelta(days=within_days)).timestamp() * 1000)

        response = (
            supabase.table("calendar_sync_channels")
            .select("*")
            .lt("expiration_timestamp", cutoff)
            .execute()
        )

        return response.data if response.data else []

    @staticmethod
    def generate_channel_id() -> str:
        """Generate unique channel ID (max 64 chars)"""
        return str(uuid.uuid4())

    @staticmethod
    def generate_channel_token(channel_id: str) -> str:
        """Generate verification token for channel"""
        return f"perm-tracker-{channel_id}"

    @staticmethod
    async def process_webhook_notification(channel_id: str, resource_id: str):
        """
        Process a webhook notification by fetching changes.
        This is called as a background task after webhook received.
        """
        # Get channel info
        channel = CalendarSyncService.get_channel(channel_id)
        if not channel:
            logger.warning(f"Unknown channel {channel_id} - ignoring notification")
            return

        # TODO (09-02): Implement actual sync logic
        # 1. Get user credentials
        # 2. Fetch changes using sync token
        # 3. Process each changed event
        # 4. Update sync token
        logger.info(
            f"Would process changes for channel {channel_id}, "
            f"user {channel['user_id']}, calendar {channel['calendar_id']}"
        )
```
  </action>
  <verify>Backend starts without import errors: `cd backend && python -c "from app.services.calendar_sync_service import CalendarSyncService"`</verify>
  <done>CalendarSyncService created with channel CRUD operations</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Migration file exists with proper syntax
- [ ] Webhook endpoint is registered in main.py
- [ ] CalendarSyncService imports without errors
- [ ] Backend starts successfully: `cd backend && uvicorn app.main:app --reload` (brief test)
</verification>

<success_criteria>
- Migration file created for calendar_sync_channels table
- Webhook endpoint handles Google Calendar notifications
- CalendarSyncService provides channel CRUD operations
- All imports work, backend starts
</success_criteria>

<output>
After completion, create `.planning/phases/09-feature-completion/09-01-SUMMARY.md`
</output>
