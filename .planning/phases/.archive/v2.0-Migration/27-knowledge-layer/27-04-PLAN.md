---
phase: 27-knowledge-layer
plan: 04
type: execute
domain: chat-integration
---

<objective>
Integrate tools into chat API with native AI SDK tool calling and enhanced system prompt.

Purpose: Connect all knowledge layer components (RAG, web search, case data) into the chat API route using native AI SDK tool calling. The LLM decides which tools to call based on the conversation. Enhanced system prompt provides PERM knowledge and tool usage guidance.

Output:
- Chat API route with `streamText` + `tools` configuration
- Tool execute functions connected to Convex queries/actions
- Enhanced system prompt with PERM knowledge and tool guidance
- Multi-step tool calling enabled (`stopWhen`)
- Tool call persistence in message history
- Human verification of chatbot tool calling quality
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
~/.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/27-knowledge-layer/27-RESEARCH.md
@.planning/phases/27-knowledge-layer/27-CONTEXT.md
@.planning/phases/27-knowledge-layer/27-01-SUMMARY.md
@.planning/phases/27-knowledge-layer/27-02-SUMMARY.md
@.planning/phases/27-knowledge-layer/27-03-SUMMARY.md
@.planning/FRONTEND_DESIGN_SKILL.md
@v2/src/app/api/chat/route.ts
@v2/src/lib/ai/system-prompt.ts
@v2/src/lib/ai/tools.ts

**Prior decisions affecting this phase:**
- Phase 26: Chat API route with probe-before-stream fallback established
- Phase 26: Message schema includes `toolCalls` array with status/result
- AI SDK v5 streaming pattern in use with `streamText`
- Tool definitions created in 27-03 with Zod schemas

**From Research (Best Practices):**
- Use `stopWhen(stepCountIs(n))` for multi-step (NOT deprecated `maxSteps`)
- Use `onStepFinish` callback for logging/monitoring tool calls
- Return errors as data for multi-step LLM recovery
- Use `fetchQuery` for reads, `fetchAction` for mutations in execute functions

**From 27-CONTEXT.md:**
- "Always cite sources" - Every PERM answer shows where info came from
- "Never hallucinates" - Only says things it can back up
- Quality bar: Like Claude/ChatGPT - professional, thorough

**From 27-RESEARCH.md:**
- Keep context injection under ~4K tokens
- Citation format: "[Source Title](URL)" or "per perm_flow.md" or "20 CFR 656.XX"

**Note:** Context management (summarization, caching) moved to 27-05-PLAN.md.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create enhanced system prompt with tool guidance</name>
  <files>v2/src/lib/ai/system-prompt.ts</files>
  <exploration>
    Read current v2/src/lib/ai/system-prompt.ts to understand existing structure.
    Review tool descriptions from 27-03 to avoid duplication.
  </exploration>
  <action>
    1. Rewrite src/lib/ai/system-prompt.ts with modular structure:

    ```typescript
    /**
     * PERM Tracker Chatbot System Prompt
     * Enhanced with tool guidance and citation requirements
     */

    const PERM_DOMAIN_KNOWLEDGE = `
## PERM Process Overview

You are an expert assistant for PERM Tracker, helping immigration attorneys manage PERM labor certification cases. Your knowledge includes:

**Case Status Types (5 stages):**
- PWD (Prevailing Wage Determination) - Wage determination from DOL
- Recruitment - Job postings and ads
- ETA 9089 - DOL application filing
- I-140 - USCIS immigrant petition
- Closed/Archived - Completed or withdrawn cases

**Progress Status Types (6 states):**
- Working on it (default)
- Waiting for intake
- Filed
- Approved
- Under review
- RFI/RFE (Request for Information/Evidence)

**Key Regulations:**
- PWD validity: 90 days if issued Apr 2-Jun 30, otherwise until following Jun 30
- Recruitment window: 30 days before PWD determination to PWD expiration
- ETA 9089 filing: 30-180 days after recruitment ends (must be before PWD expires)
- I-140: Must file within 180 days after ETA 9089 certification
- RFI: Strict 30-day response deadline (no extensions)
- RFE: 30-day response deadline (can request extension)
`;

    const APP_FEATURES = `
## PERM Tracker Features

- **Dashboard**: Overview with deadline widget, case statistics, upcoming deadlines
- **Cases List**: Filter, search, sort cases; export/import CSV/JSON
- **Case Detail**: Timeline view, deadline tracking, calendar sync
- **Calendar**: View all deadlines by month/week/day
- **Notifications**: Email and push notifications for deadlines
- **Settings**: Profile, notification preferences, calendar sync options
- **Chat**: AI assistant for PERM questions and case inquiries (you are here!)
`;

    const TOOL_USAGE_GUIDELINES = `
## TOOL USAGE GUIDELINES

You have access to these tools. Use them appropriately:

### query_cases
Use for ANY question about the user's specific cases.
- Use \`countOnly: true\` for "how many" questions (faster, smaller response)
- Use \`fields\` array to request only relevant data
- Combine filters for complex queries (e.g., caseStatus + hasRfe)
- Always reference cases by employer name in responses

### search_knowledge
Use for PERM regulations, requirements, deadlines, procedures.
- Use BEFORE answering regulatory questions
- Cite the source in your response (e.g., "per 20 CFR 656.17" or "per PERM guidelines")
- Do NOT use for user's specific cases

### search_web
Use ONLY for current/recent information:
- Current DOL processing times
- Recent regulation changes
- News about PERM program
- Always cite with [Title](URL) format
- Has daily limits - use sparingly

### TOOL CHAINING
You can call multiple tools to answer complex questions:
1. "Are any of my cases violating the 30-day recruitment rule?"
   → search_knowledge for rule details
   → query_cases to check user's cases

2. "What's the current processing time and do I have any cases filed recently?"
   → search_web for processing times
   → query_cases for recently filed cases
`;

    const RESPONSE_GUIDELINES = `
## Response Guidelines

- Match response length to question complexity
- Use professional language appropriate for legal/immigration context
- Be direct and helpful, avoid unnecessary hedging
- If unsure, say so rather than guessing
- Format complex information with markdown lists/headers
- Reference cases by employer name (e.g., "your Acme Corp case")
`;

    const CITATION_REQUIREMENTS = `
## CITATION REQUIREMENTS (CRITICAL)

EVERY factual claim MUST cite its source:
- PERM regulations: Cite "20 CFR 656.XX" or "per PERM guidelines"
- User's cases: Refer to case by employer name (e.g., "your Acme Corp case")
- Web results: Cite with [Source Title](URL)
- App features: Reference "in PERM Tracker settings" or similar

**ANTI-HALLUCINATION RULES:**
- NEVER invent case data, deadlines, or counts - use query_cases tool
- NEVER make up regulation numbers or dates - use search_knowledge tool
- If you can't cite it, don't say it
- If asked about something you don't know, say "I don't have confirmed information about..."
- If a tool returns no results, say so honestly
`;

    /**
     * Build the complete system prompt
     * Sections are joined with separators for clarity
     */
    export function buildSystemPrompt(): string {
      const sections = [
        PERM_DOMAIN_KNOWLEDGE,
        APP_FEATURES,
        TOOL_USAGE_GUIDELINES,
        RESPONSE_GUIDELINES,
        CITATION_REQUIREMENTS,
      ];

      return sections.join('\n\n---\n\n');
    }

    // Export for use in chat API
    export const SYSTEM_PROMPT = buildSystemPrompt();
    ```

    2. Key changes from Phase 26:
       - Added TOOL_USAGE_GUIDELINES section
       - Added tool chaining examples
       - Strengthened anti-hallucination with tool references
       - Removed dynamic context injection (tools provide context now)

    AVOID: Don't duplicate tool descriptions from tools.ts - reference tools by name only.
  </action>
  <verify>
    - TypeScript compiles
    - SYSTEM_PROMPT exports correctly
    - All sections are properly formatted with markdown
  </verify>
  <done>Enhanced system prompt with tool guidance implemented</done>
</task>

<task type="auto">
  <name>Task 2: Integrate tools into chat API route</name>
  <files>v2/src/app/api/chat/route.ts</files>
  <exploration>
    Read current v2/src/app/api/chat/route.ts to understand probe-before-stream pattern.
    Review AI SDK docs for streamText with tools and stopWhen.
  </exploration>
  <action>
    1. Update src/app/api/chat/route.ts to add tool integration:

    ```typescript
    import { streamText, tool, stopWhen, stepCountIs } from 'ai';
    import { z } from 'zod';
    import { fetchQuery, fetchAction } from 'convex/nextjs';
    import { api } from '@/convex/_generated/api';
    import { SYSTEM_PROMPT } from '@/lib/ai/system-prompt';
    import { queryCasesTool, searchKnowledgeTool, searchWebTool } from '@/lib/ai/tools';
    import { isAuthenticatedNextjs, getAuthToken } from '@convex-dev/auth/nextjs/server';
    // ... existing imports ...

    export const maxDuration = 60; // Allow longer for multi-step tool calls

    export async function POST(req: Request) {
      // Existing auth check
      const isAuthenticated = await isAuthenticatedNextjs();
      if (!isAuthenticated) {
        return new Response('Unauthorized', { status: 401 });
      }

      const { messages, conversationId } = await req.json();
      const token = await getAuthToken();

      // ... existing model selection and probe logic ...

      // Create tools with execute functions
      const tools = {
        query_cases: tool({
          ...queryCasesTool,
          execute: async (params) => {
            try {
              const result = await fetchQuery(
                api.chatCaseData.queryCases,
                params,
                { token }
              );
              return result;
            } catch (error) {
              console.error('query_cases error:', error);
              return {
                error: 'Failed to query cases',
                suggestion: 'Please try rephrasing your question',
              };
            }
          },
        }),

        search_knowledge: tool({
          ...searchKnowledgeTool,
          execute: async ({ query }) => {
            try {
              const result = await fetchAction(
                api.knowledge.searchKnowledge,
                { query },
                { token }
              );
              return result || {
                context: '',
                sources: [],
                message: 'No relevant knowledge found',
              };
            } catch (error) {
              console.error('search_knowledge error:', error);
              return {
                context: '',
                sources: [],
                error: 'Knowledge search unavailable',
              };
            }
          },
        }),

        search_web: tool({
          ...searchWebTool,
          execute: async ({ query }) => {
            try {
              const result = await fetchAction(
                api.webSearch.searchWeb,
                { query },
                { token }
              );
              return result || {
                source: 'none',
                results: [],
                message: 'No web results found',
              };
            } catch (error) {
              console.error('search_web error:', error);
              return {
                source: 'none',
                results: [],
                error: 'Web search unavailable',
              };
            }
          },
        }),
      };

      // Stream with tools enabled
      const result = streamText({
        model,  // From existing probe-before-stream logic
        system: SYSTEM_PROMPT,
        messages,
        tools,
        stopWhen: stepCountIs(5),  // Allow up to 5 tool calls
        onStepFinish: ({ stepType, toolCalls, toolResults }) => {
          // Log tool calls for debugging
          if (toolCalls?.length) {
            console.log('Tool calls:', toolCalls.map(tc => ({
              tool: tc.toolName,
              args: tc.args,
            })));
          }
        },
      });

      return result.toUIMessageStreamResponse();
    }
    ```

    2. Key integration points:
       - Spread tool definition (`...queryCasesTool`) then add `execute`
       - Pass `token` to fetchQuery/fetchAction for auth
       - Use `stopWhen(stepCountIs(5))` (not deprecated `maxSteps`)
       - Return errors as data for LLM recovery
       - Log tool calls for debugging

    3. Error handling pattern:
       - Catch errors in execute functions
       - Return structured error object (not throw)
       - LLM can recover and try different approach

    AVOID: Don't remove existing probe-before-stream fallback logic - keep it for model resilience.
  </action>
  <verify>
    - TypeScript compiles without errors
    - Chat API still works without tools (fallback models)
    - Tool calls are logged to console
    - Auth token is passed to Convex
  </verify>
  <done>Chat API route integrated with native tool calling</done>
</task>

<task type="auto">
  <name>Task 3: Update message persistence for tool calls</name>
  <files>v2/src/hooks/useChatWithPersistence.ts, v2/convex/conversationMessages.ts</files>
  <exploration>
    Read useChatWithPersistence.ts to understand onFinish callback.
    Check conversationMessages.ts for toolCalls field handling.
  </exploration>
  <action>
    1. Update useChatWithPersistence.ts onFinish callback to persist tool calls:

    ```typescript
    // In onFinish callback
    onFinish: async (message) => {
      // Extract tool calls from message if present
      const toolCalls = message.parts
        ?.filter(part => part.type === 'tool-call')
        .map(part => ({
          tool: part.toolName,
          arguments: JSON.stringify(part.args),
          result: JSON.stringify(part.result),
          status: part.result?.error ? 'error' : 'success',
          executedAt: Date.now(),
        }));

      // Persist assistant message with tool calls
      await createAssistantMessage({
        conversationId,
        content: message.content,
        toolCalls: toolCalls?.length ? toolCalls : undefined,
        metadata: {
          model: message.model,
          // ... existing metadata
        },
      });
    }
    ```

    2. Ensure conversationMessages.ts createAssistantMessage handles toolCalls:
       - Schema already supports toolCalls array (verified in explore)
       - Just need to pass through the data

    3. Handle tool result display in UI (optional enhancement):
       - Tool calls are already streamed via AI SDK
       - Results appear in message parts
       - No special rendering needed for Phase 27 (can enhance in Phase 28)

    AVOID: Don't change the streaming behavior - tool results are already included in stream.
  </action>
  <verify>
    - Tool calls are persisted to Convex
    - Reload conversation shows tool call history
    - No regression in message persistence
  </verify>
  <done>Message persistence updated for tool calls</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
    Knowledge-enhanced chatbot with native tool calling:
    - LLM decides which tools to call based on question
    - RAG search for PERM knowledge (search_knowledge tool)
    - Web search for current regulations (search_web tool)
    - Case data access with flexible filters (query_cases tool)
    - Citation requirements enforced
    - Anti-hallucination guards in system prompt
    - Multi-step tool calling enabled (up to 5 steps)
    - Tool calls persisted in message history
  </what-built>
  <how-to-verify>
    1. Start dev server: `cd v2 && pnpm dev`
    2. Log in and navigate to the chat widget
    3. Test these queries and verify the LLM uses the right tools:

    **PERM Knowledge (should use search_knowledge, cite sources):**
    - "What are the requirements for Sunday newspaper ads?"
    - "How long is a PWD valid?"
    - "What is the ETA 9089 filing window?"

    **Case Data (should use query_cases):**
    - "How many cases do I have?"
    - "Which cases are in PWD stage?"
    - "Do I have any overdue deadlines?"
    - "Which ETA 9089 cases have RFEs?"
    - "Show me cases due this week"

    **Complex/Chained (may use multiple tools):**
    - "Are any of my cases past the PWD expiration?"
    - "What's the 30-day rule and do any of my cases need attention?"

    **Web Search (should use search_web, cite URLs):**
    - "What are current DOL processing times?"

    **App Features (should answer from system prompt):**
    - "How do I add a new case?"
    - "Where can I see my calendar?"

    4. Verify each response:
       - Uses appropriate tool(s)
       - Has proper citations (CFR, case names, URLs)
       - Doesn't make up information
       - Is helpful and accurate
       - Matches quality bar (like Claude/ChatGPT)

    5. Check console logs for:
       - Tool call debugging output (tool names and args)
       - onStepFinish callbacks logged

    6. Verify tool call persistence:
       - Reload the page
       - Check conversation history still shows tool calls
       - Tool call results visible in message parts
  </how-to-verify>
  <resume-signal>Type "approved" if tool calling, citations, and persistence work correctly. Otherwise describe issues to fix</resume-signal>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] System prompt includes PERM knowledge and tool guidance
- [ ] Chat API uses streamText with tools and stopWhen
- [ ] Tool execute functions connected to Convex with auth
- [ ] Errors handled gracefully (return data, not throw)
- [ ] Tool calls logged for debugging (onStepFinish)
- [ ] Message persistence includes tool calls
- [ ] Tool calls visible after page reload
- [ ] Human verification approved
</verification>

<success_criteria>
- Native AI SDK tool calling working in chat API
- LLM correctly selects tools based on question type
- Tool results integrated into responses with citations
- Multi-step tool calling works for complex questions
- No hallucinated PERM rules or case data
- Tool call history persisted in Convex
- Human verification confirms tool calling works correctly
- Ready for 27-05 (context management)
</success_criteria>

<output>
After completion, create `.planning/phases/27-knowledge-layer/27-04-SUMMARY.md`:

# Phase 27 Plan 04: Chat API Tool Integration Summary

**[One-liner describing what shipped]**

## Accomplishments
- Native AI SDK tool calling integrated
- Enhanced system prompt with tool guidance
- Tools connected to Convex with proper auth
- Multi-step tool calling enabled (stopWhen pattern)
- Message persistence includes tool calls
- Human verification passed

## Files Created/Modified
- `v2/src/lib/ai/system-prompt.ts` - Enhanced prompt with tool guidance
- `v2/src/app/api/chat/route.ts` - Tool integration with streamText
- `v2/src/hooks/useChatWithPersistence.ts` - Tool call persistence

## Decisions Made
- Tool execute functions return errors as data (not throw) for LLM recovery
- Use stopWhen(stepCountIs(5)) for multi-step (not deprecated maxSteps)
- Log tool calls via onStepFinish for debugging

## Issues Encountered
[Problems and resolutions, or "None"]

## Next Step
Ready for 27-05-PLAN.md (Context Management: summarization + caching).
</output>
